{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa937bc7",
   "metadata": {},
   "source": [
    "# Demo app\n",
    "\n",
    "This demo app will launch a server at `localhot:8888` and expect an available Ollama server with the model `\"qwen3:0.6b\"`.\n",
    "It is a Q&A chatbot interface to find opensource tools for your needs or project _(in french)_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c11da99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import qA_Ap as qp\n",
    "\n",
    "qp.init(\n",
    "    ai=\"qwen3:0.6b\",\n",
    "    database=\"data/tools_db\",\n",
    "    api_server=8888\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccf2cbb",
   "metadata": {},
   "source": [
    "# Default app\n",
    "\n",
    "The default setup launches an API server and frontend view on `localhot:8080`.\n",
    "\n",
    "The database is a **FlatFileDB** on `\"data/qaap_db\"`.\n",
    "\n",
    "The AI is an **OllamaAIInterface** with the model `\"qwen3:1.7b\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286bdead",
   "metadata": {},
   "outputs": [],
   "source": [
    "qp.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fae57f",
   "metadata": {},
   "source": [
    "# Cloud app\n",
    "\n",
    "The database is a **BaseRowFreeApiDB**.\n",
    "\n",
    "The AI is an **CerebrasAIInterface** with the model `\"llama3.1-8b\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9315f11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import qA_Ap as qp\n",
    "from qA_Ap.app.ai.interfaces.cerebras import CerebrasAIInterface\n",
    "from qA_Ap.db.baserowfreeapidb import BaseRowFreeApiDB, BaseRowFreeApiDBTables\n",
    "\n",
    "keys = {}\n",
    "\n",
    "with open(\"keys.json\", \"r\") as file:\n",
    "    raw = file.read()\n",
    "    keys = json.loads(raw)\n",
    "\n",
    "ai = CerebrasAIInterface(\n",
    "    key=keys[\"cerebras\"], \n",
    "    model_name=\"llama3.1-8b\"\n",
    ")\n",
    "\n",
    "tables = BaseRowFreeApiDBTables(\n",
    "    documents=\"646003\",\n",
    "    documents_medias=\"650559\",\n",
    "    notes=\"648243\",\n",
    "    notes_medias=\"650572\",\n",
    "    summaries=\"648264\",\n",
    "    rag=\"648276\"\n",
    ")\n",
    "\n",
    "db = BaseRowFreeApiDB(\n",
    "    key=keys[\"baserow\"],\n",
    "    tables=tables\n",
    ")\n",
    "\n",
    "qp.init(\n",
    "    database=db,\n",
    "    ai=ai\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddc3a0b",
   "metadata": {},
   "source": [
    "# Manual database operations\n",
    "\n",
    "Here, the app is not initialized. Only the database is setup.\n",
    "\n",
    "The catalog is compiled manually then all documents with `couleurs` metadata containing the value or equal to `pink` are retrieved and displayed.\n",
    "\n",
    "Then the attribute `\"couleurs\"` is indexed, its values are retrieved from the database and displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2faed5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 documents compiled successfully\n",
      "Found Document 'Post pink' {'couleurs': 'pink'}\n",
      "Found Document 'Post pink 2' {'couleurs': 'pink'}\n",
      "Found Document 'Post pink and noir' {'couleurs': ['pink', 'noir']}\n",
      "Found Document 'Post pink et rouge' {'couleurs': ['pink', 'rouge']}\n",
      "All existing 'couleurs' values ['noir', 'bleu', 'pink', 'orange', 'rouge']\n"
     ]
    }
   ],
   "source": [
    "from qA_Ap.db.flatfiledb import FlatFileDB\n",
    "from qA_Ap.app.catalog import compile_catalog, compile_attribute, find_documents_by_metadata\n",
    "from qA_Ap.globals import globals\n",
    "\n",
    "globals.database = FlatFileDB(\"data/test_db\")\n",
    "\n",
    "compile_catalog()\n",
    "\n",
    "results = find_documents_by_metadata(\n",
    "    attribute=\"couleurs\",\n",
    "    value=\"pink\"\n",
    ")\n",
    "for document in results:\n",
    "    print(f\"Found Document '{document[\"title\"]}'\",document[\"metadata\"])\n",
    "\n",
    "compile_attribute(\"couleurs\")\n",
    "\n",
    "couleurs = globals.database.get_attribute_values(\"couleurs\")\n",
    "\n",
    "print(\"All existing 'couleurs' values\",couleurs.splitlines())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c9ddc6",
   "metadata": {},
   "source": [
    "# Manual query\n",
    "\n",
    "Here everything is setup manually for using the RAG functionalities manually. It is similar to using the init method with `api_server` set to `False`.\n",
    "\n",
    "The vectostore is created and the query is done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57e04d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 documents\n",
      "Document 'Amulet' divided into 1 chunks, Document 'Ardour' divided into 1 chunks, Document 'Aseprite' divided into 1 chunks, Document 'Audacity' divided into 1 chunks, Document 'Blender' divided into 1 chunks, Document 'Calibre' divided into 1 chunks, Document 'Darktable' divided into 1 chunks, Document 'Firefox' divided into 1 chunks, Document 'foobar2000' divided into 1 chunks, Document 'GIMP' divided into 1 chunks, Document 'Godot' divided into 1 chunks, Document 'Grav' divided into 1 chunks, Document 'Inkscape' divided into 1 chunks, Document 'Jitsi' divided into 1 chunks, Document 'kMeet' divided into 2 chunks, Document 'Krita' divided into 1 chunks, Document 'LibreOffice' divided into 1 chunks, Document 'LMMS' divided into 1 chunks, Document 'LÖVE' divided into 1 chunks, Document 'Nextcloud' divided into 1 chunks, Document 'OBS' divided into 1 chunks, Document 'Rufus' divided into 1 chunks, Document 'Scribus' divided into 1 chunks, Document 'Shotcut' divided into 1 chunks, Document 'Sumatra PDF' divided into 1 chunks, Document 'Super Productivity' divided into 1 chunks, Document 'VLC' divided into 1 chunks, \n",
      "Vector store saved\n",
      "=====================\n",
      "Vous cherchez un logiciel open source pour créer un jeu avec vos propres modèles 3D, et notamment un moteur de jeu. \n",
      "\n",
      "Je vous recommande d'utiliser Godot est un moteur de jeu open source, léger et polyvalent, conçu pour créer des jeux 2D et 3D. [Document 2 - Godot]\n",
      "\n",
      "Si vous cherchez un logiciel plus complet pour la modélisation, l'animation et la création de jeux, vous pourriez utiliser Blender, qui est un logiciel gratuit et open source de création 3D, largement utilisé pour la modélisation, l’animation, le rendu, le montage vidéo et même le développement de jeux. [Document 1 - Blender]\n",
      "\n",
      "[Document 1 - Blender, Document 2 - Godot]\n",
      "=====================\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "import qA_Ap as qp\n",
    "from qA_Ap.app.ai.methods import query, vectorize_documents\n",
    "from qA_Ap.app.ai.faissvectorstore import FaissVectorStore\n",
    "from qA_Ap.app.ai.interfaces.cerebras import CerebrasAIInterface\n",
    "from qA_Ap.db.flatfiledb import FlatFileDB\n",
    "from qA_Ap.globals import globals\n",
    "\n",
    "\n",
    "keys = {}\n",
    "\n",
    "with open(\"keys.json\", \"r\") as file:\n",
    "    raw = file.read()\n",
    "    keys = json.loads(raw)\n",
    "\n",
    "globals.database = FlatFileDB(\"data/tools_db\")\n",
    "\n",
    "globals.path_to_emmbeddings_model = \"data/llms/Qwen3-Embedding-0.6B\"\n",
    "\n",
    "globals.ai_interface = CerebrasAIInterface(\n",
    "        key=keys[\"cerebras\"], \n",
    "        model_name=\"llama3.1-8b\"\n",
    "    )\n",
    "globals.vectorstoreclass = FaissVectorStore\n",
    "\n",
    "globals.system_prompt = qp.default_system_prompt\n",
    "\n",
    "globals.object_of_search = \"tools\"\n",
    "\n",
    "vectorize_documents()\n",
    "\n",
    "print(\"=====================\")\n",
    "response = query(\"Je cherche un logiciel opensource pour pour créer un jeu avec mes propres modèles 3D.\")\n",
    "for chunk in response:\n",
    "    print(chunk,end=\"\",flush=True)\n",
    "print(\"\\n=====================\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
