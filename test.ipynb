{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c11da99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import qA_Ap as qp\n",
    "\n",
    "qp.init(\n",
    "    ai=\"qwen3:0.6b\",\n",
    "    database=\"data/tools_db\",\n",
    "    api_server=8888\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccf2cbb",
   "metadata": {},
   "source": [
    "# Default app\n",
    "\n",
    "The default setup launches an API server and frontend view on `localhot:8080`.\n",
    "\n",
    "The database is a **FlatFileDB** on `\"data/qaap_db\"`.\n",
    "\n",
    "The AI is an **OllamaAIInterface** with the model `\"qwen3:1.7b\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286bdead",
   "metadata": {},
   "outputs": [],
   "source": [
    "qp.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fae57f",
   "metadata": {},
   "source": [
    "# Cloud app\n",
    "\n",
    "The database is a **BaseRowFreeApiDB**.\n",
    "\n",
    "The AI is an **CerebrasAIInterface** with the model `\"llama3.1-8b\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9315f11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import qA_Ap as qp\n",
    "from qA_Ap.app.ai.interfaces.cerebras import CerebrasAIInterface\n",
    "from qA_Ap.db.baserowfreeapidb import BaseRowFreeApiDB, BaseRowFreeApiDBTables\n",
    "\n",
    "ai = CerebrasAIInterface(\n",
    "    key=\"csk-pt2x2jd9yrvddfr92rp4wx4fvd2wkfv8mjewvp3t59f4vyvk\", \n",
    "    model_name=\"llama3.1-8b\"\n",
    ")\n",
    "\n",
    "tables = BaseRowFreeApiDBTables(\n",
    "    documents=\"646003\",\n",
    "    documents_medias=\"650559\",\n",
    "    notes=\"648243\",\n",
    "    notes_medias=\"650572\",\n",
    "    summaries=\"648264\",\n",
    "    rag=\"648276\"\n",
    ")\n",
    "\n",
    "db = BaseRowFreeApiDB(\n",
    "    token=\"tyesLJsYXhYHyR2LBI2jZcUG711W1iUu\",\n",
    "    tables=tables\n",
    ")\n",
    "\n",
    "qp.init(\n",
    "    database=db,\n",
    "    ai=ai\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddc3a0b",
   "metadata": {},
   "source": [
    "# Manual database operations\n",
    "\n",
    "Here, the app is not initialized. Only the database is setup.\n",
    "\n",
    "The catalog is compiled manually then all documents with `couleurs` metadata containing the value or equal to `pink` are retrieved and displayed.\n",
    "\n",
    "Then the attribute `\"couleurs\"` is indexed, its values are retrieved from the database and displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2faed5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Document 'Post3' {'couleurs': 'pink'}\n",
      "Found Document 'Post3 copy' {'couleurs': 'pink'}\n",
      "Found Document 'Post3' {'couleurs': 'pink'}\n",
      "All existing 'couleurs' values ['pink', 'rouge', 'bleu']\n"
     ]
    }
   ],
   "source": [
    "from qA_Ap.db.flatfiledb import FlatFileDB\n",
    "from qA_Ap.app.catalog import compile_catalog, compile_attribute, find_documents_by_metadata\n",
    "from qA_Ap.globals import globals\n",
    "\n",
    "globals.database = FlatFileDB(\"data/test_db\")\n",
    "\n",
    "compile_catalog()\n",
    "\n",
    "results = find_documents_by_metadata(\n",
    "    attribute=\"couleurs\",\n",
    "    value=\"pink\"\n",
    ")\n",
    "for document in results:\n",
    "    print(f\"Found Document '{document[\"title\"]}'\",document[\"metadata\"])\n",
    "\n",
    "compile_attribute(\"couleurs\")\n",
    "\n",
    "couleurs = globals.database.get_attribute_values(\"couleurs\")\n",
    "\n",
    "print(\"All existing 'couleurs' values\",couleurs.splitlines())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c9ddc6",
   "metadata": {},
   "source": [
    "# Manual query\n",
    "\n",
    "Here everything is setup manually for using the RAG functionalities manually. It is similar to using the init method with `api_server` set to `False`.\n",
    "\n",
    "The vectostore is created and the query is done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57e04d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 documents\n",
      "1 chunks\n",
      "1 chunks\n",
      "1 chunks\n",
      "1 chunks\n",
      "1 chunks\n",
      "1 chunks\n",
      "1 chunks\n",
      "1 chunks\n",
      "1 chunks\n",
      "1 chunks\n",
      "1 chunks\n",
      "1 chunks\n",
      "Vector store saved\n",
      "=====================\n",
      "Je te recommande d'utiliser Godot pour créer un jeu avec tes propres modèles 3D. C'est un moteur de jeu open source qui se distingue par son interface intuitive et son langage de script intégré (GDScript).\n",
      "\n",
      "[Document 2 - Godot, Document 1 - Blender]\n",
      "=====================\n"
     ]
    }
   ],
   "source": [
    "import qA_Ap as qp\n",
    "from qA_Ap.app.ai.methods import query, vectorize_documents\n",
    "from qA_Ap.app.ai.vectorstore import FaissVectorStore\n",
    "from qA_Ap.app.ai.interfaces.cerebras import CerebrasAIInterface\n",
    "from qA_Ap.db.flatfiledb import FlatFileDB\n",
    "from qA_Ap.globals import globals\n",
    "\n",
    "\n",
    "globals.database = FlatFileDB(\"data/tools_db\")\n",
    "\n",
    "globals.path_to_emmbeddings_model = \"data/llms/Qwen3-Embedding-0.6B\"\n",
    "\n",
    "globals.ai_interface = CerebrasAIInterface(\n",
    "        key=\"csk-pt2x2jd9yrvddfr92rp4wx4fvd2wkfv8mjewvp3t59f4vyvk\", \n",
    "        model_name=\"llama3.1-8b\"\n",
    "    )\n",
    "globals.vectorstoreclass = FaissVectorStore\n",
    "\n",
    "globals.system_prompt = qp.default_system_prompt\n",
    "\n",
    "globals.object_of_search = \"tools\"\n",
    "\n",
    "vectorize_documents()\n",
    "\n",
    "print(\"=====================\")\n",
    "response = query(\"Je cherche un logiciel opensource pour pour créer un jeu avec mes propres modèles 3D.\")\n",
    "for chunk in response:\n",
    "    print(chunk,end=\"\",flush=True)\n",
    "print(\"\\n=====================\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
